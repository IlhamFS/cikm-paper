\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\iffalse
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  Paso, Texas USA} 
\acmYear{1997}
\copyrightyear{2016}

\acmPrice{15.00}
\fi

\begin{document}

\title{Keyphrase Extraction from User Generated Contents on Medical Domain}
\iffalse
\titlenote{Produces the permission block, and
  copyright information}
\subtitle{Extended Abstract}
\subtitlenote{The full version of the author's guide is available as
  \texttt{acmart.pdf} document}
\fi

% The default list of authors is too long for headers}
%\renewcommand{\shortauthors}{F. Ilham et al.}


\begin{abstract}
The tremendous amount of user-generated contents, such as the questions about symptoms and diseases being asked by a user in online forums, or blog posts about dietary and fitness, are potential sources for enriching knowledge in medical document retrieval and health-related text mining applications. Understanding those various contents is simply not a trivial task. Therefore, reducing the complex characteristics of the contents into structured information could be very beneficial for the text interpretation process. We argue that there are many missing pieces of information when we rely merely on medical entities (i.e., using Medical Entity Recognizer) as our main information. In our work, we use keyphrases extraction techniques to extract more important information about the concept of the document. Previous works on keyphrases extraction mostly focused on a general domain, long and formal written documents, which make them perform poorly when being applied to user-generated contents and medical documents. Moreover, we propose several deep learning architectures, such as bi-directional long-short term memory networks, convolutional neural networks, and their combinations as the models for extracting keyphrases. Furthermore, we leverage word embeddings, medical concepts from a knowledge base, and linguistic components as our features. The proposed algorithm achieved F1 score of 82.41\%. This result outperforms state of the art system for extracting keyphrases using a statistical model.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%


\keywords{keyphrase extraction, health-related text mining, deep learning, recurrent neural networks, convolutional neural networks}


\maketitle

\section{Introduction}
Health-related or question-answering forum is becoming a trend today. With those forum, seeking health information and asking questions to doctors is pretty much easier. As a result, there is a growing need for enriching medical-related knowledge, for which it can be very valuable for several tasks in IR and NLP \cite{cao2010automatically}. However, understanding those various health-related contents, especially from an online forum, is simply not a trivial task since they are written in free text format (i.e. unstructured format), and often prone to grammatical and typographical glitches. Therefore, reducing the complex characteristics of the textual contents, including but not limited to linguistic variations, into structured information could be very beneficial for the text interpretation process. 

One possible solution is harnessing medical entity recognizer to extract medical terms that represent the document they belong. However, we argue that there are many missing pieces of information when we merely rely on medical entities or terminologies as our main information for representing a particular document. Hence, we leverage keyphrase to cover more valuable information. Keyphrases are usually selected phrases or clauses that can capture the main topic of a given document \cite{turney2000learning}. They can provide readers with highly valuable and representative information, such that looking at keyphrases is sufficient to understand the whole body of a document.

In this paper, we only focus the task of keyphrase extraction on Indonesian medical questions from online forums, such as alodokter\footnote{www.alodokter.com}, health detik \footnote{health.detik.com}, dokter.id \footnote{www.dokter.id}, klikdokter \footnote{www.klikdokter.com}. We present a new keyphrase extraction techniques to extract more important information about the patient intentions and needs, which expressed inside Indonesian medical questions. Furthermore, we also propose a new definition of keyphrases, which is based on our observation of health-related and user-generated questions. Actually, our final goal is to develop medical question answering systems to assist physicians or people obtaining health information. The work presented in this paper is absolutely in line with our goal since important keyphrases of a medical question can be used to formulate a query for the passage or question retrieval subsystem \cite{gong2009improving}. The following example shows the results of keyphrase extraction in a medical document:
	\textit{\\Dok , saya sering sekali merasa \textbf{\emph{kram pada perut kanan bagian atas}} disertai \textbf{detak jantung yang cepat} serta \textbf{keringat dingin} dan \textbf{pusing}. Dan saat kambuh seperti itu, \textbf{nafas sangat sakit}. apakah ada hubungannya dengan \textbf{diet mayo}? terima kasih sblumnya dok.}
	\texttt{(Doc, i frequently feel a \textbf{cramp on upper right stomach} with \textbf{fasten heart beat} also \textbf{cold sweat} and \textbf{headache}. And when the symptom occur it's \textbf{very hurt when breathing}. is there any connection with \textbf{moyo diet}? thanks before)}
	
It can be seen on the example that keyphrases can be a word, phrase, or even clause. Furthermore, there are many grammatical errors and abbreviation, such as \texttt{"sy"} for the replacement of the word \texttt{"saya (I)"}. It is also worth to note that keyphrase \texttt{"diet mayo (mayo diet)"} is not part of medical entity categories listed by Wahid \cite{skripsiWahid} and Abid \cite{skripsiKakAbid} research. Thus, extracting keyphrase for getting patient needs is not a trivial task. 

In our work, we use similar approach as in Cao et al. \cite{cao2010automatically}, which treats keyphrase extraction as a sequence labeling task. The difference is that, in our experiment, we employed and combined various deep learning architectures, such as convolutional neural networks and bi-directional long short-term memory networks, to exploit high level features between neighboring word positions. To improve the quality of our model, we leverage several new hand-crafted features that can handle our keyphrase extraction problems in medical user-generated content, such as word importance and word stickiness features. The word importance feature is enable to rank words in a document by their importance value. The more important a word is to the content of document, the higher its "keywordness" value would seem to be. In addition, we also propose word stickiness feature to make our model constructs keyphrases

\section{Related Works}
In general, keyphrase extraction methods can be divided into two groups: unsupervised ranking (statistical) approach and supervised machine learning approach. For the unsupervised line of research, keyphrase extraction is formulated as a ranking problem, in which each candidate keyphrase is assigned a score that represents its keywordness value. The well-known research in unsupervised approach are RAKE \cite{rake} which use the ratio of word degree and frequency to rank terms. There is also Mihalcea and Tarau \cite{mihalcea2004textrank} who developed a graph-based approach which treats words as vertices and constructs edge between words using co-occurrence.

On the other hand, supervised machine learning approach requires training data that contains a collection of documents with their labeled keywords which is often very difficult to obtain. Using this approach, keyphrase extraction is usually treated as a classification or sequence labeling task in the level of words or phrases. The first step of this approach generates candidate keyphrases from a particular document. Finally, every candidate keyphrase in the document will be classified as either a keyphrase or non-keyphrase. The well-known method for this approach is KEA \cite{witten1999kea}, they use machine-learning (i.e., Naive Bayes) for classifying candidate keyphrases. The utilization of neural networks in classifying candidate keyphrases also conducted by \cite{ekpNeuralNetworks}. Recently, a well-known supervised approach for keyphrase extraction is based on sequence labeling problem (\cite{zhang2008automatic}, \cite{cao2010automatically}, \cite{zhang2016keyphrase}). The assumption behind this model is that the decision on whether a particular word serves as a keyword is affected by the information from its neighboring word positions.

For medical document, Sarkar and Kamal \cite{ekpMedicalDocumentHybrid} use a hybrid medical knowledge base and statistical approach to extract keyphrases from medical articles. They use stopwords to split candidate keyphrases, then candidates are ranked with two aspects: PF-IDF (Phrase Frequency * Inverse Document Frequency) and domain knowledge which is extracted from medical article.

Unfortunately, there are limited works regarding the task of keyphrase extraction from user generated on medical question, especially in Indonesian language. Similar research in English language has been conducted by Cao et al. \cite{cao2010automatically} use Conditional Random Fields (CRFs) for extracting keywords from medical questions in online health forum. They use information, such as word location and length as features in their experiments.

\section{METHODOLOGY}
In this work, we view keyphrase extraction problem as a sequence labeling task. That is, given a medical question containing $N$ words $w = (w_1, w_2,...,w_N)$, we want to find the best sequence of labels $y = (y_1, y_2,..., y_N)$, in which each label is determined using probabilities $P(y_i|w_{i-l},...,w_{i+l},y_{i-l},...,y_{i+l})$ where $l$ is a small number.

Because we have a small dataset, our model would have a small learning material and an end-to-end learning approach will not work well. As a result, we leveraged nine handcrafted features that can help our model to characterize the sequence of keyphrases.

\textbf{Word Embedding (We).} In the experiments, we use word embedding as input to the neural network. A skip-gram model from Mikolov \cite{mikolov2013wordembed} research was used to generate these 128-dimensional vectors for documents in evaluation data. The dimension of the vector was chosen based on \cite{skripsiWahid} experiment. The word embedding we used in this work were trained using a document that we gathered from Indonesia online forum, medical article, and medical question answering forum. With this feature, slank words can be handled better.

\textbf{Medical Dictionary (Md).} In our experiment, we leverage a medical knowledge base feature using a medical dictionary. The dictionary was built by combining disease, symptom, treatment, and drug dictionaries from \cite{skripsiKakAbid} research. The rationale behind this feature is intentions and needs of patients is more focused on their disease, symptom, treatment, and drug. Based on this feature, we classified words by their appearance in the medical dictionary. We represent this feature as one-hot-vector. 

\textbf{Word Length (Wl).} This feature represents the length of each word (i.e., the number of characters in every word). This feature is based on Cao et al. \cite{cao2010automatically} research on keyphrase extraction in medical question. This feature is added because domain-specific words (e.g. "tuberculosis") tend to be lengthy when compared to common English words, and there is a correlation between the length of a word and its IDF value \cite{cao2010automatically}.

\textbf{Word Position (Wp).} We also adapted word position as feature based on Cao et al. \cite{cao2010automatically} research. Based on their observation, an important term sometimes appears toward the end of a clinical question. For example, "medicine for bell's palsy" appear towards the end of a question "what is the best medicine for bell's palsy?". 

\textbf{POS-tag (Pt).} POS-tag of words was also added as our feature. POS-tag may give model grammatical information and a better understanding of ambiguous words. By our observation, many keyphrases have a common POS pattern. We use Stanford Part-Of-Speech Tagger and a model which pre-trained by Dinakaramani \cite{dinakaramani2014designing}. We represent our POS tag feature as one-hot-vector.

\textbf{Medical Entity (Me).} We use medical entity which was annotated by Wahid \cite{skripsiWahid} using four categories: drug, treatment, symptom, disease. By our observation, medical entities are sometimes part of keyphrases. Furthermore, medical entities can provide more information about drug or disease which not available in training data or a medical dictionary. We also use one-hot-vector to represent this feature.

\textbf{Abbreviation and Acronym (Wa).} We also identified words by their appearance in abbreviation or acronym dictionary gathered by Abid \cite{skripsiKakAbid}. We observed that important word may not be shortened by the users, such as "cancer", "flu", "bell's palsy". One-hot-vector is used to classify whether a word is an abbreviation/acronym or not. For example, the word "\textit{mengapa (why)}" sometimes is abbreviated to \texttt{mngp} by some patients.

\textbf{Word Importance (Wi).} The purpose of this feature is to rank words in a document by their importance. To extract this feature, we adapted  TextRank \cite{mihalcea2004textrank} algorithm for ranking words in a document. They represent words as vertices in the graph and the distance between words as edges. However, in building an undirected graph, we use a word similarity as a weight for edges by using our pre-trained word embedding model to calculate cosine similarity between two word vectors. Two words have a connected edge if their similarity is not negative. Moreover, we use a modified PageRank \cite{page1999pagerank} algorithm that consider edges weight in the calculation. Formally, let $G = (V, E)$ be an undirected graph with the set of vertices V and set of edges E, where E is a subset of $V \times V$. For a given vertex $V_i$ let $In(V_i)$ be the set of vertices that point to it (predecessors) and let $Out(V_i)$ be the set of vertices that vertex $V_i$ points to (successors). The modified PageRank formula that proposed by \cite{mihalcea2004textrank} can be seen in Formula \ref{eq:pagerank}.
\begin{equation}\label{eq:pagerank}
WS(V_{i})=(1-d) + d * \sum_{V_{i} \in In(V_{i})} \frac{w_{ji}}{\sum_{V_{i} \in Out(V_{j})}}w_{jk}
\end{equation}


\textbf{Word Stickiness (Ws).} As a keyphrase, a sequence must be in a valid order. There is some noise such as misuse punctuation by users. For example, "\textit{Saya mengalami pusing pada jidat sakit perut dan pandangan kabur} (I am having a headache on forehead stomachache and blurred vision)", there is no comma between "jidat (forehead)", "sakit perut (stomachache)" and "dan (and)". Our model may mistake the sequence "(jidat sakit perut)forehead stomachache" as a keyphrase. Based on that problem, we propose a feature that may capture how likely of a given word is occurred together with the word before and after. We use Pointwise Mutual Information (PMI) of a bigram probability to capture the likeness. Formula \ref{eq:pmi} is the formula for calculating the PMI value. In that formula, $p(x)$ is the occurrence probability of word $x$, $p(y)$ is the occurrence probability of word $y$, and $p(x, y)$ is the probability of word $x$ and $y$ co-occur together.
\begin{equation}\label{eq:pmi}
PMI(x,y)=log(\frac{P(x, y)}{P(x).P(y)})
\end{equation}
The feature function is formally described as $f_s(w) = [x, y]$ where $w$ is a word, x is the stickiness value between w and the word before, and y is the stickiness value between w and the word before. For example, the word "\texttt{cancer}" in sentence "\texttt{How to prevent cancer doc?}", the feature value is $f_s(cancer) = [0.56, 0.1]$ where $f_s$ is feature stickiness feature function. It is worth to note that the word "\texttt{cancer}" is rarely co-occur with the word "\texttt{doc}". Therefore, the stickiness value between the word "cancer" and "doc" is relatively smaller than "prevent".

We process the sequences word by word. All Features are extracted and concatenated into one vector from every word as the input representation of the model. The output of our model are labels which describe whether a word is either part of keyphrase or not. 

We introduce Convolutional Neural Networks (CNNs) to exploit high-level features between neighboring word positions. Based on our observation, a keyphrase is. For example, "Doc, I have a frequent back pain. What happen?". The keyphrase for the previous example is "frequent back pain". In order to know that "back" is part of keyphrase, we need information from the word "frequent" which give an intensity of a symptom and "pain" which refer to "back pain" as the main term. With CNNs, we argue that our model can capture the surrounding information of a word. The output of the CNNs layer will be fed into our next layer which is B-LSTM.

To get a better inference, information from the past and future of sequences can be integrated. This approach is proven effective in sequence labeling task such as semantic role labeling \cite{SMRzhou2015end} and named entity recognition \cite{ma2016end}. Therefore, we utilized bi-directional LSTM (B-LSTM) for extracting structural knowledge by processing sequences both forward and backward. We concatenate the output from both LSTM. We build up to two layers of B-LSTM.

Finally, the locally normalized distribution over output labels is computed via a softmax layer.

We also experimented on customizing the way we input the features underneath our aforementioned model. Instead of concatenating all features into one vector, which can be seen in Formula \ref{eq:concat}, we tried to give some kind of weighting for every feature we have. 
\begin{equation}\label{eq:concat}
Z =  concatenate(F_{1}, F_{2}, ..F_{9})
\end{equation}
We argue that each feature has different contribution to the model. In order to do so, we create a new layer underneath our model to do the weighting scenario. Formally, let $Z$ is the input representation and $F_{i}$ are the extracted feature in vector form, $W_i \in {\rm I\!R^{a_i \times b}}$ where the length of $a$ is equal to $F_{i}$ and $b$ is the input representation vector. The following equation to weight all features can be seen in below:
\begin{equation}
Z =  tanh(W _{1}.F_{1} + W_{2}.F_{2} + .. + W_{n}.F_{9})
\end{equation}


\section{Evaluations and Results}
\subsection{Data Collection}
To develop training data, we collected question-answer pairs which previously crawled by Abid \cite{skripsiKakAbid} and Wahid \cite{skripsiWahid} from Indonesian question-answering medical forum. Then, we selected 416 distinct question-answer pairs and removed the answer section for every pair because it is not relevant for obtaining patient intentions and needs. Finally, we manually annotated those questions. The statistical information of our data can be seen in Table \ref{tab:descriptive_stats}.

\begin{table}
	\caption{Statistical information of dataset. W, K, $\bar{N}_{w}$, $\bar{N}_{k}$ are the total of words, number of keyphrases, average number of words, and average number of keyphrases in each question, respectively.}
	\label{tab:descriptive_stats}
	\begin{tabular}{lcccc}
		\toprule
		\#questions&W&K&$\bar{N}_{w}$&$\bar{N}_{k}$\\
		\midrule
		416 & 26747  & 64.76 & 1861 & 4.49 \\
		
		\bottomrule
	\end{tabular}
\end{table}
\subsection{Evaluation}
For our experiments, we employed 10-cross-validation on our dataset. We use partial evaluation by Seki et al. \cite{seki2003probabilistic} to get precision, recall, F1-measure for evaluation metrics. This evaluation is used because we treat keyphrases as sequences of words.  


\subsection{Results}
\begin{table}
	\caption{Model Scenario Results}
	\label{tab:model_scenario}
	\begin{tabular}{lccc}
		\toprule
		Models&Precision&Recall&F-Measure\\
		\midrule
		RAKE & 43.24\% & 68.19\% & 52.90\% \\
		
		CRF & 63.44\% & 64.94\% & 62.52\% \\
		\midrule
		B-LSTM & 81.88\% & \textbf{83.05\%} & 82.37\% \\
		
		CNN-B-LSTM & \textbf{82.00\%} & 82.99\% & \textbf{82.41\%} \\
		
		W-CNN-B-LSTM & 81.08\% & 81.18\% & 81.01\% \\
		\bottomrule
	\end{tabular}
\end{table}


For comparison, we implemented RAKE \cite{rake} and CRF \cite{cao2010automatically}, which use unsupervised and supervised approach. For CRF, we use the same features proposed above. We also conducted an experiment to proof the effectiveness of our CNN layer by comTM with CNNs layer(CNN-B-LSTM). Furthermore, we also compared our model with or without weighting layer (W-CNN-B-LSTM).

As we can see in Table \ref{tab:model_scenario}, RAKE and CRF underperformed on Indonesian user-generated medical question since RAKE were specially devised for formal text. For CRF, based on our observation from the result provided by CRF, the method failed to predict long sequences as a keyphrase. Our CNNs layer also shows improvement in precision and F1 score when compared to standard B-LSTM. We suggest that CNNs layer can extract more features implicitly from neighboring words. However, our experiment weighting layer failed to provide some improvement. 

\subsection{Analysis}
We performed an analysis to the aforementioned model, the result shown there are several errors. Some of the error are uncompleted keyphrases. For example, "pusing pada (headache on)", "obat untuk (medicine for)". Our model also failed to capture complex medicine name and disease. This is due to our small data set and not all medicine and disease are captured in our medical knowledge base or medical entities. Moreover, there are also special case that our model failed to handle. For example, "penyembuhan untuk sakit kepala dan tenggorokan (treatment for headache and sore throat)", the keyphrase need to be captured as a whole because "sore throat" have a connection with the word "treatment". But our model failed to capture that connection and extracted "treatment for headache" and "sore throat" separately instead.

We also ablate our mode by removing our features one by one. As we can see in Table \ref{tab:ablation}, F1 score always dropped when we removed one feature. Hence, we can say that all of our features are effective for this task.
 \begin{table}
	\caption{Average Change in Performance When Removing Each Feature}
	\label{tab:ablation}
	\begin{tabular}{cccc}
		\toprule
		Removed Features&Precision&Recall&F-Measure\\
		\midrule
            We & -4.08 & -18.34 & -12.84 \\
            Md & -8.35 & +0.24 & -3.84 \\
            Wl & -8.65 & +0.49 & -3.87 \\
            Wp & -9.77 & +2.44 & -3.5 \\
            Pt & -4.33 & -0.98 & -2.52 \\
            Wa & -5.57 & -1.96 & -3.62 \\
            Wi & -0.32 & -0.49 & -0.42 \\
            Me & -4.63 & +0.49 & -1.89 \\
            Ws & -7.62 & -2.2 & -4.73 \\
		\bottomrule
	\end{tabular}
\end{table}
\section{Conclusion}
We have proposed a model to address the task of keyphrase extraction on Indonesian user-generated medical domain. Extracting information patient intentions and needs on user-generated medical contents is not a trivial task due to the fact that the content is usually short, contain many medical terms, and written in an unstructured format, as opposed to formal text. Our model is based on sequence labeling task that employs deep learning approach using convolutional neural networks and bi-directional lstm. Several handcrafted features were proposed, including word importance to detect important word in a document and word stickiness for handling unstructured writing. Although our model outperforms baseline methods for keyphrase extraction, further improvements are needed.

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference} 

\end{document}
\grid
